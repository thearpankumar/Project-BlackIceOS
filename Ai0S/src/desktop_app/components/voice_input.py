"""
Voice Input Widget - Real-time voice transcription with Gemini 2.0 Flash
Professional voice input component with visual feedback and real-time transcription.
"""

import asyncio
import threading
import time
from typing import Callable, Optional, Dict, Any
import logging
import pyaudio
import wave
import io
from pathlib import Path

import customtkinter as ctk
from PIL import Image, ImageTk
import numpy as np

# Professional theme will be passed as parameter
from ...backend.models.ai_models import AIModels
from ...config.settings import get_settings


logger = logging.getLogger(__name__)


class VoiceInputWidget(ctk.CTkFrame):
    """Professional voice input widget with real-time transcription."""
    
    def __init__(self, parent, theme, ipc_client=None, on_voice_start: Callable = None, 
                 on_voice_stop: Callable = None, on_transcript: Callable[[str], None] = None):
        super().__init__(parent)
        
        self.theme = theme
        self.ipc_client = ipc_client
        self.on_voice_start = on_voice_start
        self.on_voice_stop = on_voice_stop
        self.on_transcript = on_transcript
        self.settings = get_settings()
        
        # Voice recording state
        self.is_recording = False
        self.is_listening = False
        self.audio_thread: Optional[threading.Thread] = None
        self.audio_buffer = []
        
        # Audio configuration
        self.audio_config = {
            "format": pyaudio.paInt16,
            "channels": 1,
            "rate": 16000,
            "chunk": 1024,
            "record_seconds": 30  # Max recording length
        }
        
        # PyAudio instance
        self.audio = pyaudio.PyAudio()
        
        # Visual feedback
        self.animation_active = False
        self.volume_levels = []
        
        # Setup UI
        self._setup_ui()
        
        # Start continuous listening mode if enabled
        if self.settings.voice_settings.get("continuous_listening", False):
            self._start_continuous_listening()
    
    def _setup_ui(self) -> None:
        """Setup the voice input user interface."""
        
        self.configure(
            corner_radius=12,
            fg_color=self.theme.get_color("bg_secondary"),
            border_width=1,
            border_color=self.theme.get_color("border")
        )
        
        # Main container
        self.main_container = ctk.CTkFrame(
            self,
            fg_color="transparent"
        )
        self.main_container.pack(fill="both", expand=True, padx=20, pady=20)
        
        # Header
        self.header_frame = ctk.CTkFrame(
            self.main_container,
            fg_color="transparent",
            height=40
        )
        self.header_frame.pack(fill="x", pady=(0, 15))
        
        self.title_label = ctk.CTkLabel(
            self.header_frame,
            text="Voice Input",
            font=self.theme.get_font("heading_small"),
            text_color=self.theme.get_color("text_primary")
        )
        self.title_label.pack(side="left")
        
        self.status_label = ctk.CTkLabel(
            self.header_frame,
            text="Ready",
            font=self.theme.get_font("body_small"),
            text_color=self.theme.get_color("text_muted")
        )
        self.status_label.pack(side="right")
        
        # Voice visualization container
        self.viz_frame = ctk.CTkFrame(
            self.main_container,
            height=120,
            corner_radius=8,
            fg_color=self.theme.get_color("bg_primary")
        )
        self.viz_frame.pack(fill="x", pady=(0, 15))
        self.viz_frame.pack_propagate(False)
        
        # Voice level canvas for visualization
        self.voice_canvas = ctk.CTkCanvas(
            self.viz_frame,
            height=100,
            bg=self.theme.get_color("bg_primary"),
            highlightthickness=0
        )
        self.voice_canvas.pack(fill="both", expand=True, padx=10, pady=10)
        
        # Control buttons container
        self.controls_frame = ctk.CTkFrame(
            self.main_container,
            fg_color="transparent"
        )
        self.controls_frame.pack(fill="x", pady=(0, 15))
        
        # Record button (main action)
        self.record_button = self.theme.create_styled_button(
            self.controls_frame,
            text="ðŸŽ¤ Start Recording",
            style="primary",
            command=self._toggle_recording,
            width=150
        )
        self.record_button.pack(side="left", padx=(0, 10))
        
        # Push-to-talk button
        self.ptt_button = self.theme.create_styled_button(
            self.controls_frame,
            text="Push to Talk",
            style="secondary",
            width=120
        )
        self.ptt_button.pack(side="left", padx=(0, 10))
        
        # Bind push-to-talk events
        self.ptt_button.bind("<Button-1>", self._start_ptt)
        self.ptt_button.bind("<ButtonRelease-1>", self._stop_ptt)
        
        # Settings button
        self.settings_button = self.theme.create_styled_button(
            self.controls_frame,
            text="âš™ï¸",
            style="secondary",
            command=self._show_settings,
            width=40
        )
        self.settings_button.pack(side="right")
        
        # Continuous listening toggle
        self.continuous_var = ctk.BooleanVar(
            value=self.settings.voice_settings.get("continuous_listening", False)
        )
        
        self.continuous_check = ctk.CTkCheckBox(
            self.controls_frame,
            text="Continuous Listening",
            variable=self.continuous_var,
            command=self._toggle_continuous_listening,
            font=self.theme.get_font("body_small")
        )
        self.continuous_check.pack(side="right", padx=(0, 10))
        
        # Transcription display
        self.transcription_frame = ctk.CTkFrame(
            self.main_container,
            corner_radius=8,
            fg_color=self.theme.get_color("bg_primary"),
            border_width=1,
            border_color=self.theme.get_color("border")
        )
        self.transcription_frame.pack(fill="both", expand=True)
        
        # Transcription text area
        self.transcription_text = ctk.CTkTextbox(
            self.transcription_frame,
            font=self.theme.get_font("body_medium"),
            wrap="word",
            height=100
        )
        self.transcription_text.pack(fill="both", expand=True, padx=10, pady=10)
        
        # Action buttons for transcription
        self.transcription_actions = ctk.CTkFrame(
            self.transcription_frame,
            fg_color="transparent",
            height=40
        )
        self.transcription_actions.pack(fill="x", padx=10, pady=(0, 10))
        
        self.clear_button = self.theme.create_styled_button(
            self.transcription_actions,
            text="Clear",
            style="small",
            command=self._clear_transcription,
            width=60
        )
        self.clear_button.pack(side="left")
        
        self.copy_button = self.theme.create_styled_button(
            self.transcription_actions,
            text="Copy",
            style="small",
            command=self._copy_transcription,
            width=60
        )
        self.copy_button.pack(side="left", padx=(5, 0))
        
        self.send_button = self.theme.create_styled_button(
            self.transcription_actions,
            text="Send to Chat",
            style="primary",
            command=self._send_to_chat,
            width=100
        )
        self.send_button.pack(side="right")
    
    def _toggle_recording(self) -> None:
        """Toggle voice recording on/off."""
        
        if self.is_recording:
            self._stop_recording()
        else:
            self._start_recording()
    
    def _start_recording(self) -> None:
        """Start voice recording."""
        
        try:
            self.is_recording = True
            self.audio_buffer = []
            
            # Update UI
            self.record_button.configure(text="ðŸ›‘ Stop Recording")
            self.status_label.configure(text="Recording...")
            self.status_label.configure(text_color=self.theme.get_color("error"))
            
            # Notify parent component
            if self.on_voice_start:
                self.on_voice_start()
            
            # Start audio recording thread
            self.audio_thread = threading.Thread(target=self._record_audio)
            self.audio_thread.daemon = True
            self.audio_thread.start()
            
            # Start visual feedback
            self._start_voice_visualization()
            
            logger.info("Voice recording started")
            
        except Exception as e:
            logger.error(f"Failed to start recording: {e}")
            self._update_status("Recording failed")
            self.is_recording = False
    
    def _stop_recording(self) -> None:
        """Stop voice recording and process audio."""
        
        if not self.is_recording:
            return
        
        try:
            self.is_recording = False
            
            # Update UI
            self.record_button.configure(text="ðŸŽ¤ Start Recording")
            self.status_label.configure(text="Processing...")
            self.status_label.configure(text_color=self.theme.get_color("warning"))
            
            # Notify parent component
            if self.on_voice_stop:
                self.on_voice_stop()
            
            # Wait for audio thread to finish
            if self.audio_thread and self.audio_thread.is_alive():
                self.audio_thread.join(timeout=2)
            
            # Stop visualization
            self._stop_voice_visualization()
            
            # Process recorded audio
            asyncio.create_task(self._process_audio())
            
            logger.info("Voice recording stopped")
            
        except Exception as e:
            logger.error(f"Failed to stop recording: {e}")
            self._update_status("Processing failed")
    
    def _record_audio(self) -> None:
        """Record audio in background thread."""
        
        try:
            stream = self.audio.open(
                format=self.audio_config["format"],
                channels=self.audio_config["channels"],
                rate=self.audio_config["rate"],
                input=True,
                frames_per_buffer=self.audio_config["chunk"]
            )
            
            while self.is_recording:
                data = stream.read(self.audio_config["chunk"])
                self.audio_buffer.append(data)
                
                # Calculate volume for visualization
                audio_np = np.frombuffer(data, dtype=np.int16)
                volume = np.abs(audio_np).mean()
                self.volume_levels.append(volume)
                
                # Keep only recent volume levels
                if len(self.volume_levels) > 50:
                    self.volume_levels = self.volume_levels[-50:]
            
            stream.stop_stream()
            stream.close()
            
        except Exception as e:
            logger.error(f"Audio recording error: {e}")
            self.is_recording = False
    
    async def _process_audio(self) -> None:
        """Process recorded audio and get transcription."""
        
        try:
            if not self.audio_buffer:
                self._update_status("No audio recorded")
                return
            
            # Convert audio buffer to bytes
            audio_data = b''.join(self.audio_buffer)
            
            # Create WAV file in memory
            wav_buffer = io.BytesIO()
            with wave.open(wav_buffer, 'wb') as wav_file:
                wav_file.setnchannels(self.audio_config["channels"])
                wav_file.setsampwidth(self.audio.get_sample_size(self.audio_config["format"]))
                wav_file.setframerate(self.audio_config["rate"])
                wav_file.writeframes(audio_data)
            
            wav_buffer.seek(0)
            
            # Send audio data to backend for transcription via IPC
            # Note: Since this runs in a thread, we'll use a thread-safe approach
            transcription = self._request_transcription_sync(wav_buffer.getvalue())
            
            if transcription:
                self._display_transcription(transcription)
                self._update_status("Transcription complete")
                
                # Call callback if provided
                if self.on_transcript:
                    self.on_transcript(transcription)
            else:
                self._update_status("No speech detected")
                
        except Exception as e:
            logger.error(f"Audio processing failed: {e}")
            self._update_status("Processing failed")
    
    def _start_ptt(self, event) -> None:
        """Start push-to-talk recording."""
        if not self.is_recording:
            self._start_recording()
    
    def _stop_ptt(self, event) -> None:
        """Stop push-to-talk recording."""
        if self.is_recording:
            self._stop_recording()
    
    def _toggle_continuous_listening(self) -> None:
        """Toggle continuous listening mode."""
        
        enabled = self.continuous_var.get()
        
        if enabled:
            self._start_continuous_listening()
        else:
            self._stop_continuous_listening()
    
    def _start_continuous_listening(self) -> None:
        """Start continuous listening mode."""
        
        self.is_listening = True
        self._update_status("Listening continuously...")
        
        # Start background listening thread
        listening_thread = threading.Thread(target=self._continuous_listen)
        listening_thread.daemon = True
        listening_thread.start()
        
        logger.info("Continuous listening started")
    
    def _stop_continuous_listening(self) -> None:
        """Stop continuous listening mode."""
        
        self.is_listening = False
        self._update_status("Ready")
        logger.info("Continuous listening stopped")
    
    def _continuous_listen(self) -> None:
        """Continuous listening background process."""
        
        # This would implement voice activity detection
        # and automatic transcription when speech is detected
        # For now, it's a placeholder
        
        while self.is_listening:
            time.sleep(0.1)
            # TODO: Implement voice activity detection
    
    def _start_voice_visualization(self) -> None:
        """Start voice level visualization."""
        
        self.animation_active = True
        self._update_visualization()
    
    def _stop_voice_visualization(self) -> None:
        """Stop voice level visualization."""
        
        self.animation_active = False
        self.voice_canvas.delete("all")
    
    def _update_visualization(self) -> None:
        """Update voice level visualization."""
        
        if not self.animation_active:
            return
        
        try:
            # Clear canvas
            self.voice_canvas.delete("all")
            
            # Get canvas dimensions
            canvas_width = self.voice_canvas.winfo_width()
            canvas_height = self.voice_canvas.winfo_height()
            
            if canvas_width <= 1 or canvas_height <= 1:
                self.after(50, self._update_visualization)
                return
            
            # Draw volume levels as bars
            if self.volume_levels:
                bar_width = max(1, canvas_width // len(self.volume_levels[-30:]))
                recent_levels = self.volume_levels[-30:]
                
                for i, level in enumerate(recent_levels):
                    # Normalize level to canvas height
                    normalized_level = min(level / 5000, 1.0)  # Adjust scaling as needed
                    bar_height = int(normalized_level * canvas_height * 0.8)
                    
                    x = i * bar_width
                    y = canvas_height - bar_height
                    
                    # Color based on volume level
                    if normalized_level > 0.7:
                        color = self.theme.get_color("error")
                    elif normalized_level > 0.4:
                        color = self.theme.get_color("warning")
                    else:
                        color = self.theme.get_color("primary")
                    
                    self.voice_canvas.create_rectangle(
                        x, y, x + bar_width - 1, canvas_height,
                        fill=color, outline=""
                    )
            
            # Schedule next update
            self.after(50, self._update_visualization)
            
        except Exception as e:
            logger.debug(f"Visualization update error: {e}")
            self.after(50, self._update_visualization)
    
    def _display_transcription(self, text: str) -> None:
        """Display transcription in the text area."""
        
        current_text = self.transcription_text.get("1.0", "end-1c")
        
        if current_text.strip():
            new_text = current_text + "\n\n" + text
        else:
            new_text = text
        
        self.transcription_text.delete("1.0", "end")
        self.transcription_text.insert("1.0", new_text)
    
    def _clear_transcription(self) -> None:
        """Clear transcription text."""
        
        self.transcription_text.delete("1.0", "end")
    
    def _copy_transcription(self) -> None:
        """Copy transcription to clipboard."""
        
        text = self.transcription_text.get("1.0", "end-1c")
        if text.strip():
            self.clipboard_clear()
            self.clipboard_append(text)
            self._update_status("Copied to clipboard")
    
    def _send_to_chat(self) -> None:
        """Send transcription to chat interface."""
        
        text = self.transcription_text.get("1.0", "end-1c")
        if text.strip() and self.on_transcript:
            self.on_transcript(text)
            self._update_status("Sent to chat")
    
    def _show_settings(self) -> None:
        """Show voice input settings dialog."""
        
        # Create settings dialog
        settings_window = ctk.CTkToplevel(self)
        settings_window.title("Voice Settings")
        settings_window.geometry("400x300")
        settings_window.transient(self.winfo_toplevel())
        settings_window.grab_set()
        
        # Settings content (placeholder)
        label = ctk.CTkLabel(
            settings_window,
            text="Voice Settings",
            font=self.theme.get_font("heading_medium")
        )
        label.pack(pady=20)
        
        # Close button
        close_btn = self.theme.create_styled_button(
            settings_window,
            text="Close",
            command=settings_window.destroy
        )
        close_btn.pack(pady=20)
    
    def _update_status(self, status: str, color: Optional[str] = None) -> None:
        """Update status label."""
        
        self.status_label.configure(text=status)
        if color:
            self.status_label.configure(text_color=color)
        else:
            self.status_label.configure(text_color=self.theme.get_color("text_muted"))
    
    def _request_transcription_sync(self, audio_data: bytes) -> str:
        """Send audio data to backend for transcription (thread-safe)."""
        
        try:
            if not self.ipc_client or not self.ipc_client.is_connected():
                logger.warning("IPC client not available for transcription")
                return "[Transcription requires backend connection]"
            
            # Convert audio data to base64 for JSON transport
            import base64
            audio_b64 = base64.b64encode(audio_data).decode('utf-8')
            
            # For now, return a placeholder until IPC transcription is fully implemented
            logger.info("Audio data prepared for backend transcription")
            return "[Backend transcription placeholder - audio capture successful]"
            
        except Exception as e:
            logger.error(f"Transcription preparation failed: {e}")
            return f"[Transcription error: {e}]"
    
    def cleanup(self) -> None:
        """Cleanup resources."""
        
        try:
            self.is_recording = False
            self.is_listening = False
            self.animation_active = False
            
            if self.audio_thread and self.audio_thread.is_alive():
                self.audio_thread.join(timeout=1)
            
            self.audio.terminate()
            
        except Exception as e:
            logger.error(f"Voice input cleanup error: {e}")